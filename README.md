# CAFÃ‰-GB â€” Paper 1 Experiments

## Step 1
```bash
python run_all.py --stage cafe --dataset andmal2020
python run_all.py --stage cafe --dataset bodmas
python run_all.py --stage cafe --dataset embod
```

## Phase 2 â€” k-selection (lightweight, once)
```bash
python run_all.py --stage k --dataset embod
python run_all.py --stage k --dataset andmal2020
python run_all.py --stage k --dataset bodmas
```

## Phase 3 â€” Classification (moderate)
```bash
python run_all.py --stage classify --dataset andmal2020
python run_all.py --stage classify --dataset bodmas
python run_all.py --stage classify --dataset embod
```

## Phase 4 â€” Analysis & stats (cheap)
```bash
python run_all.py --stage correlation
python run_all.py --stage stats
python run_all.py --stage shap --dataset embod
python run_all.py --stage shap --dataset andmal2020
python run_all.py --stage shap --dataset bodmas
```

## Run
```bash
# CAFÃ‰-GB only (heavy)
python run_all.py --stage cafe --dataset andmal2020

# k-selection (once, reference dataset)
python run_all.py --stage k --dataset embod

# Classification (cheap)
python run_all.py --stage classify --dataset bodmas
# Analysis & stats (cheap)



Perfect â€” youâ€™re at the **right execution point**.
Below is the **exact, safe, step-by-step command sequence** from **this moment onward**, assuming:

* You have **finished CAFÃ‰-GB for BODMAS**
* You want **final k = 100**
* You want **all experiments completed cleanly**
* You want **NO re-runs and NO wasted compute**

Iâ€™ll give you **only commands**, in the **correct order**, with **one-line context**.

---

## ğŸ”´ STEP 1 â€” Finish CAFÃ‰-GB for remaining datasets (if not done)

If **only BODMAS is done**, run CAFÃ‰-GB for the others.

```bash
python run_all.py --stage cafe --dataset andmal2020
python run_all.py --stage cafe --dataset embod
```

âœ” Heavy step
âœ” Run one dataset at a time
âœ” Can be stopped/resumed

---

## ğŸŸ¡ STEP 2 â€” k-selection (run ONCE)

You said **k = 100**.
If you **already ran k-selection earlier**, skip this step.

Otherwise, run **only on reference dataset** (recommended: `embod`):

```bash
python run_all.py --stage k --dataset embod
```

ğŸ‘‰ Inspect:

```bash
results/tables/embod/table3_k_selection.xlsx
```

âœ” Confirm `k = 100`

---

## ğŸŸ¢ STEP 3 â€” Lock k = 100 (IMPORTANT)

Edit `config/k.yaml`:

```yaml
k: 100
```

(No command needed if already set.)

---

## ğŸŸ¢ STEP 4 â€” Classification (ALL datasets)

Now run classifiers using **fixed k = 100**.

```bash
python run_all.py --stage classify --dataset bodmas
python run_all.py --stage classify --dataset andmal2020
python run_all.py --stage classify --dataset embod
```

âœ” Fast compared to CAFÃ‰-GB
âœ” Uses cached features
âœ” Produces Tables 6â€“8

---

## ğŸ”µ STEP 5 â€” Verify runtime & memory profiling

Check that profiling was logged:

```bash
cat results/tables/runtime_memory.csv
```

âœ” Needed for **Scalability Table (Table 5)**

---

## ğŸ”µ STEP 6 â€” Verify all outputs exist

### CAFÃ‰-GB outputs

```bash
ls fs/cafe_gb/bodmas
ls fs/cafe_gb/andmal2020
ls fs/cafe_gb/embod
```

You should see:

```
aggregated_importance_seed*.parquet
```

---

### Classification outputs

```bash
ls results/tables/bodmas
ls results/tables/andmal2020
ls results/tables/embod
```

You should see:

```
performance_seed42.xlsx
performance_seed52.xlsx
...
```

---

## ğŸ”µ STEP 7 â€” Aggregate results (NO more heavy runs)

At this point:

* All **experiments are DONE**
* Only **analysis & plotting** remains

(No more `run_all.py` calls needed.)

---

## ğŸ“Œ FINAL EXECUTION SUMMARY (copyâ€“paste safe)

```bash
# CAFÃ‰-GB
python run_all.py --stage cafe --dataset bodmas
python run_all.py --stage cafe --dataset andmal2020
python run_all.py --stage cafe --dataset embod

# k-selection (once)
python run_all.py --stage k --dataset embod

# Fix k = 100 in config/k.yaml

# Classification
python run_all.py --stage classify --dataset bodmas
python run_all.py --stage classify --dataset andmal2020
python run_all.py --stage classify --dataset embod
```

---

## ğŸ¯ You are DONE with computation

From here on:

* ğŸ“Š Tables
* ğŸ“ˆ Plots
* âœï¸ Paper writing

No more expensive runs.

---

# Rerun Experiments
---

# ğŸ” GENERAL RULE (memorize this)

> **You rerun a stage by deleting *only that stageâ€™s outputs*.
> Never delete upstream artifacts unless the change affects them.**

Pipeline dependency is:

```
CAFÃ‰-GB  â†’  k-selection  â†’  Classification  â†’  Analysis
```

---

# ğŸŸ¥ STAGE 1 â€” CAFÃ‰-GB (Feature Selection)

## When do you need to rerun CAFÃ‰-GB?

Rerun **ONLY IF you change**:

* chunk_size / overlap (`config/cafe_gb.yaml`)
* feature importance model (GB â†’ LGBM)
* feature preprocessing
* random seeds
* CAFÃ‰-GB code (`fs/cafe_gb/*`)

### âŒ Do NOT rerun CAFÃ‰-GB if you only change:

* k
* classifiers
* metrics
* plotting
* saving models

---

## How to rerun CAFÃ‰-GB (three levels)

### ğŸ”¹ A. Rerun CAFÃ‰-GB for ONE seed (recommended)

```bash
rm fs/cafe_gb/bodmas/aggregated_importance_seed42.parquet
python run_all.py --stage cafe --dataset bodmas
```

Only seed 42 reruns.

---

### ğŸ”¹ B. Rerun CAFÃ‰-GB for ONE dataset (all seeds)

```bash
rm -rf fs/cafe_gb/bodmas
python run_all.py --stage cafe --dataset bodmas
```

---

### ğŸ”¹ C. Rerun CAFÃ‰-GB for ALL datasets

```bash
rm -rf fs/cafe_gb
python run_all.py --stage cafe
```

âš ï¸ Very expensive â€” do this only if unavoidable.

---

# ğŸŸ¨ STAGE 2 â€” k-selection

## When do you need to rerun k-selection?

Rerun **ONLY IF you change**:

* CAFÃ‰-GB results
* k-selection logic (`stats/k_selection.py`)
* k candidate list

### âŒ Do NOT rerun if:

* only classifiers changed
* only reporting changed

---

## How to rerun k-selection

### ğŸ”¹ A. Rerun for ONE dataset

```bash
rm results/tables/bodmas/table3_k_selection.xlsx
rm -rf results/figures/bodmas
python run_all.py --stage k --dataset bodmas
```

---

### ğŸ”¹ B. Rerun for reference dataset only (recommended)

```bash
rm results/tables/embod/table3_k_selection.xlsx
rm -rf results/figures/embod
python run_all.py --stage k --dataset embod
```

---

# ğŸŸ© STAGE 3 â€” Classification

## When do you need to rerun classification?

Rerun **IF you change**:

* k (`config/k.yaml`)
* classifiers / hyperparameters
* model-saving logic
* metrics
* profiling code

### âŒ Do NOT rerun if:

* CAFÃ‰-GB unchanged
* k unchanged
* only plotting changes

---

## How to rerun classification

### ğŸ”¹ A. Rerun ONE seed (fast, profiling / sanity)

```bash
rm results/tables/bodmas/performance_seed42.xlsx
python run_all.py --stage classify --dataset bodmas
```

---

### ğŸ”¹ B. Rerun ONE dataset (all seeds)

```bash
rm -rf results/tables/bodmas
python run_all.py --stage classify --dataset bodmas
```

---

### ğŸ”¹ C. Rerun ALL datasets

```bash
rm -rf results/tables
python run_all.py --stage classify
```

---

# ğŸŸ¦ STAGE 4 â€” Profiling (runtime & memory)

## When do you need to rerun profiling?

Profiling happens **only when a stage actually runs**.

So:

* If a stage is skipped â†’ no profiling
* To profile â†’ force that stage to rerun

### Recommended profiling strategy

* CAFÃ‰-GB â†’ 1 seed per dataset
* Classification â†’ 1 seed per dataset

---

### Example: Profile CAFÃ‰-GB

```bash
rm fs/cafe_gb/bodmas/aggregated_importance_seed42.parquet
python run_all.py --stage cafe --dataset bodmas
```

---

### Example: Profile classification

```bash
rm results/tables/bodmas/performance_seed42.xlsx
python run_all.py --stage classify --dataset bodmas
```

---

# ğŸŸª STAGE 5 â€” Analysis / Tables / Plots

## When do you need to rerun analysis?

Rerun **ONLY IF you change**:

* aggregation scripts
* plotting scripts
* statistical tests

### âŒ Do NOT rerun any experiments for this.

Just rerun scripts, e.g.:

```bash
python stats/aggregate_results.py
python plots/make_figures.py
```

(No `run_all.py` involved.)

---

# ğŸ“Œ QUICK DECISION TABLE

| You changedâ€¦ | Rerun                        |
| ------------ | ---------------------------- |
| k value      | Classification               |
| CAFÃ‰-GB code | CAFÃ‰-GB â†’ k â†’ Classification |
| Classifier   | Classification               |
| Metrics      | Classification               |
| Plots only   | Nothing                      |
| Profiling    | Rerun that stage             |
| Seeds        | CAFÃ‰-GB + Classification     |

---

# âœ… SAFE DEFAULT (when unsure)

If youâ€™re unsure what changed, this is safe and not too expensive:

```bash
rm -rf results/tables/bodmas
python run_all.py --stage classify --dataset bodmas
```

---

## ğŸ¯ Final advice (important)

* **Delete outputs, never inputs**
* **Rerun the minimum stage**
* **Never rerun CAFÃ‰-GB unless absolutely required**
* Your current setup is **textbook-correct**





